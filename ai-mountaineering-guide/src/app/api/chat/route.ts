import { google } from '@ai-sdk/google';
import { streamText } from 'ai';

// Allow responses up to 30 seconds
export const maxDuration = 30;

export async function POST(req: Request) {
  try {
    // Parse the incoming messages from the frontend
    const { messages } = await req.json();

    console.log("1. Request received, calling Gemini 2.5 Flash...");

    // Call the Gemini model using the correct and newest version
    const result = await streamText({
      model: google('gemini-2.5-flash'),
      system: `Ð¢Ð¸ ÑÐ¸ ÐµÐºÑÐ¿ÐµÑ€Ñ‚ÐµÐ½ Ð¸ ÐµÐ½Ñ‚ÑƒÑÐ¸Ð°Ð·Ð¸Ñ€Ð°Ð½ Ð¿Ð»Ð°Ð½Ð¸Ð½ÑÐºÐ¸ Ð²Ð¾Ð´Ð°Ñ‡ Ð·Ð° Ð‘ÑŠÐ»Ð³Ð°Ñ€Ð¸Ñ.
      Ð¢Ð²Ð¾ÑÑ‚Ð° Ð·Ð°Ð´Ð°Ñ‡Ð° Ðµ Ð´Ð° Ð¿Ð¾Ð¼Ð°Ð³Ð°Ñˆ Ð½Ð° Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð¸Ñ‚ÐµÐ»Ð¸Ñ‚Ðµ Ð´Ð° ÑÐ¸ Ð½Ð°Ð¼Ð¸Ñ€Ð°Ñ‚ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸, Ñ…Ð¸Ð¶Ð¸ Ð¸ Ð²ÑŠÑ€Ñ…Ð¾Ð²Ðµ.
      Ð‘ÑŠÐ´Ð¸ ÐºÑ€Ð°Ñ‚ÑŠÐº, Ñ‚Ð¾Ñ‡ÐµÐ½ Ð¸ Ð²Ð¸Ð½Ð°Ð³Ð¸ Ð´Ð°Ð²Ð°Ð¹ ÑÑŠÐ²ÐµÑ‚Ð¸ Ð·Ð° Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ Ð¸ ÐµÐºÐ¸Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ°, ÐºÐ¾Ð³Ð°Ñ‚Ð¾ Ðµ Ð½ÑƒÐ¶Ð½Ð¾.
      Ð˜Ð·Ð¿Ð¾Ð»Ð·Ð²Ð°Ð¹ ÐµÐ¼Ð¾Ð´Ð¶Ð¸Ñ‚Ð°, Ð·Ð° Ð´Ð° Ðµ Ð¿Ð¾-Ð¿Ñ€Ð¸ÑÑ‚Ð½Ð¾ Ñ‡ÐµÑ‚ÐµÐ½ÐµÑ‚Ð¾.`,
      messages,
      // Catch any errors that happen during the AI generation process
      onError: ({ error }) => {
        console.error('\nðŸš¨ GEMINI STREAM ERROR ðŸš¨');
        console.error(error);
      }
    });

    console.log("2. Gemini stream successfully started. Sending to frontend...");

    // Return the stream to the client
    return result.toDataStreamResponse();

  } catch (error) {
    // Catch any general server errors
    console.error('\nðŸš¨ GENERAL BACKEND ERROR ðŸš¨');
    console.error(error);
    return new Response('Internal Server Error', { status: 500 });
  }
}